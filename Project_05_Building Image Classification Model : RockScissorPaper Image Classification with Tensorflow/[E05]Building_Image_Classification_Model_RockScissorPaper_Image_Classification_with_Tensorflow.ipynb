{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[E05]Building Image Classification Model : RockScissorPaper Image Classification with Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **[ Project 05. Building Image Classification Model : RockScissorPaper Image Classification with Tensorflow ]**\n"
      ],
      "metadata": {
        "id": "OKt_0TUpJnxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################################## \b 구글드라이브 마운트 #####################################################\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# \b구글드라이브 마운트 \n",
        "root = \"/content/drive\"\n",
        "drive.mount(root, force_remount=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb1c27d3-e515-44c4-81c5-b08cda4c19c0",
        "id": "oAVdkTqZJnxo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "################### 데이터프레임으로 이미지 불러오고 크기 조정 ##################3\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "import numpy as np \n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# 데이터 경로 지정 \n",
        "googledrive_path = \"MyDrive/github/ML-DL-Project\"\n",
        "project_dir = \"Project_05_Building Image Classification Model : RockScissorPaper Image Classification with Tensorflow\"\n",
        "data_path = os.path.join(root,googledrive_path,project_dir,\"data\")\n",
        "\n",
        "class ImageProcessing:\n",
        "\n",
        "  def __init__(self,img_path):\n",
        "    self.img_path = img_path\n",
        "\n",
        "  def define_image_path(self):\n",
        "    img_extension_list = [ '.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP']\n",
        "    self.img_path_list = [data for data in Path(self.img_path).glob('**/*') if data.suffix in img_extension_list] #이미지파일 찾기\n",
        "    return self.img_path_list\n",
        "\n",
        "\n",
        "  def resize_image(self,target_width,target_height):\n",
        "    for img_path in self.img_path_list:\n",
        "      \n",
        "      img = Image.open((img_path))\n",
        "      img = img.resize((int(target_width), int(target_height)))\n",
        "      new_root_folder = str(img_path.parent.parent) + \"_resize_\"+str(target_width)+\"x\"+str(target_height)\n",
        "      new_folder = new_root_folder+\"/\"+str(img_path.parts[-2])\n",
        "      img_name = img_path.parts[-1]\n",
        "      resize_file = new_folder +\"/\" + img_name\n",
        "      if not os.path.exists(new_folder):\n",
        "        # Path(new_folder).mkdir()\n",
        "        Path(new_folder).mkdir(parents=True, exist_ok=True)\n",
        "        print(new_folder, \" 생성완료\")\n",
        "\n",
        "\n",
        "      if not os.path.exists(resize_file):\n",
        "        img.save(resize_file)\n",
        "\n",
        "    print(\"resize 완료\")\n",
        "    img_extension_list = [ '.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP']\n",
        "    self.img_path_list = [data for data in Path(new_root_folder).glob('**/*') if data.suffix in img_extension_list]\n",
        "\n",
        "\n",
        "  def set_image_label(self,label_dict=None):\n",
        "    if  label_dict == None:\n",
        "      label_dict = dict([(value.parts[-1],idx) for idx, value in enumerate(Path(data_path).glob('*/')) ])\n",
        "    self.label_list = [label_dict[img_path.parts[-2]] for img_path in self.img_path_list] \n",
        "    return self.label_list\n",
        "\n",
        "  \n",
        "  def load_dataset(self,target_width,target_height):\n",
        "    number_of_data = len(self.img_path_list)\n",
        "    # img_array_list = [np.array(Image.open(img_path),dtype=np.int32) for img_path in self.img_path_list ]\n",
        "    imgs=np.zeros(number_of_data*target_width*target_height*3,dtype=np.int32).reshape(number_of_data,target_width,target_height,3)\n",
        "    \n",
        "    idx = 0\n",
        "    for img_path in self.img_path_list:\n",
        "      img = np.array(Image.open(img_path).convert(\"RGB\"),dtype=np.int32)\n",
        "      # print(img.mode)\n",
        "      imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
        "      idx=idx+1\n",
        "    labels = np.array(self.set_image_label())\n",
        "    return imgs,labels\n",
        "\n",
        "      \n",
        "    print(\"--\")\n",
        "    print('class to index: ',label_dict)\n",
        "    print('label_list: ',label_list)\n",
        "    print('img_array_list: ',img_array_list)\n"
      ],
      "metadata": {
        "id": "1MDJS07FJnxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = ImageProcessing(data_path)\n",
        "img_path_list = a.define_image_path()\n",
        "\n",
        "a.resize_image(28,28)\n",
        "\n",
        "X, y = a.load_dataset(28,28)\n",
        "\n",
        "\n",
        "X_norm = X/255.0   # 입력은 0~1 사이의 값으로 정규화\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "313ce364-0504-4879-d9eb-4a3a5ca2ede7",
        "id": "g5CeBrZyJnxo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/github/ML-DL-Project/Project_05_Building Image Classification Model : RockScissorPaper Image Classification with Tensorflow/data_resize_28x28/rock  생성완료\n",
            "/content/drive/MyDrive/github/ML-DL-Project/Project_05_Building Image Classification Model : RockScissorPaper Image Classification with Tensorflow/data_resize_28x28/scissor  생성완료\n",
            "/content/drive/MyDrive/github/ML-DL-Project/Project_05_Building Image Classification Model : RockScissorPaper Image Classification with Tensorflow/data_resize_28x28/paper  생성완료\n",
            "resize 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3,  random_state=1004)\n",
        "X_train_scaled,X_test_scaled,y_train,y_test = train_test_split(X_norm, y, test_size=0.3,  random_state=1004)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XOi_cpkYJnxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Conv2D(16, (5,5), activation='relu', input_shape=(28,28,3)))\n",
        "model.add(keras.layers.MaxPool2D(4,4))\n",
        "model.add(keras.layers.Conv2D(32,(3,3),activation='relu'))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(32, activation='relu'))\n",
        "model.add(keras.layers.Dense(15, activation='relu'))\n",
        "model.add(keras.layers.Dense(3, activation='softmax'))\n",
        "\n",
        "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f434400b-0d32-4e33-d5d3-2b74bda9428b",
        "id": "mWg3jQY2Jnxp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model에 추가된 Layer 개수:  8\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 24, 24, 16)        1216      \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 6, 6, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 4, 4, 32)          4640      \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 2, 2, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 15)                495       \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 3)                 48        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,527\n",
            "Trainable params: 10,527\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "                loss = 'sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy']    )\n",
        "\n",
        "print(\"====== 정규화 x ============\")\n",
        "model.fit(X_train,y_train, epochs=10)\n",
        "print(\"====== 정규화 o ============\")\n",
        "model.fit(X_train_scaled,y_train, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9a84d17-b64c-47db-f569-61e7e5721ed7",
        "id": "rLpJh-f1Jnxp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====== 정규화 x ============\n",
            "Epoch 1/10\n",
            "62/62 [==============================] - 2s 15ms/step - loss: 1.6009 - accuracy: 0.8090\n",
            "Epoch 2/10\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.1961 - accuracy: 0.9458\n",
            "Epoch 3/10\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.0771 - accuracy: 0.9772\n",
            "Epoch 4/10\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.0580 - accuracy: 0.9833\n",
            "Epoch 5/10\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.0812 - accuracy: 0.9772\n",
            "Epoch 6/10\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.0871 - accuracy: 0.9721\n",
            "Epoch 7/10\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.0732 - accuracy: 0.9772\n",
            "Epoch 8/10\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.0411 - accuracy: 0.9873\n",
            "Epoch 9/10\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.0224 - accuracy: 0.9914\n",
            "Epoch 10/10\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.0080 - accuracy: 0.9985\n",
            "====== 정규화 o ============\n",
            "Epoch 1/10\n",
            "62/62 [==============================] - 2s 26ms/step - loss: 0.9452 - accuracy: 0.7741\n",
            "Epoch 2/10\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.6068 - accuracy: 0.8511\n",
            "Epoch 3/10\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.3840 - accuracy: 0.9058\n",
            "Epoch 4/10\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.2586 - accuracy: 0.9468\n",
            "Epoch 5/10\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.1799 - accuracy: 0.9696\n",
            "Epoch 6/10\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.1455 - accuracy: 0.9716\n",
            "Epoch 7/10\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.1080 - accuracy: 0.9813\n",
            "Epoch 8/10\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.0859 - accuracy: 0.9838\n",
            "Epoch 9/10\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.0756 - accuracy: 0.9868\n",
            "Epoch 10/10\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.0631 - accuracy: 0.9899\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9a123b5210>"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"====== 정규화 x ============\")\n",
        "test_loss, test_accuracy = model.evaluate(X_test,y_test, verbose=2)\n",
        "print(\"test_loss: {} \".format(test_loss))\n",
        "print(\"test_accuracy: {}\".format(test_accuracy))\n",
        "\n",
        "\n",
        "print(\"====== 정규화 o ============\")\n",
        "test_loss, test_accuracy = model.evaluate(X_test_scaled,y_test, verbose=2)\n",
        "print(\"test_loss: {} \".format(test_loss))\n",
        "print(\"test_accuracy: {}\".format(test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d39b7e7-e396-4381-ec53-08debb3a6e5d",
        "id": "J7WHwqtEJnxp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====== 정규화 x ============\n",
            "27/27 - 0s - loss: 154.1409 - accuracy: 0.7237 - 151ms/epoch - 6ms/step\n",
            "test_loss: 154.1409454345703 \n",
            "test_accuracy: 0.7237308025360107\n",
            "====== 정규화 o ============\n",
            "27/27 - 0s - loss: 0.0607 - accuracy: 0.9870 - 160ms/epoch - 6ms/step\n",
            "test_loss: 0.06066831201314926 \n",
            "test_accuracy: 0.9870129823684692\n"
          ]
        }
      ]
    }
  ]
}
